{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Poisoned Goat Experiment Pipeline\n",
        "\n",
        "This notebook orchestrates the full experiment:\n",
        "1. Generate contaminated addition datasets with different contamination rates (10%, 50%, 100%)\n",
        "2. Fine-tune tiedong/goat-lora-7b on each contaminated dataset\n",
        "3. Evaluate each fine-tuned model on BIG-bench arithmetic dataset\n",
        "\n",
        "## Colab Setup\n",
        "\n",
        "If running on Google Colab, make sure to:\n",
        "1. Enable GPU runtime (Runtime → Change runtime type → GPU)\n",
        "2. Install dependencies (run the setup cell below)\n",
        "3. Authenticate with HuggingFace if needed: `huggingface-cli login`\n",
        "\n",
        "**Note:** The code uses FP16 (half precision) training, which doesn't require bitsandbytes. This avoids CUDA setup issues with bitsandbytes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Colab setup - uncomment if running on Google Colab\n",
        "# Install packages (bitsandbytes NOT required - we use FP16 instead)\n",
        "# !pip install -q transformers datasets peft accelerate fire tqdm\n",
        "\n",
        "# IMPORTANT: finetune.py has been updated to use FP16 (half precision) instead of 8-bit\n",
        "# This avoids bitsandbytes CUDA setup issues\n",
        "# FP16 training works well and doesn't require bitsandbytes\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "# Try these base models in order of preference:\n",
        "# Option 1: huggyllama/llama-7b (usually more accessible)\n",
        "# Option 2: decapoda-research/llama-7b-hf (original, might need auth)\n",
        "BASE_MODEL = \"huggyllama/llama-7b\"  # Change to \"decapoda-research/llama-7b-hf\" if needed\n",
        "INITIAL_LORA_WEIGHTS = \"tiedong/goat-lora-7b\"  # Starting point: pre-trained goat model\n",
        "\n",
        "# Experiment parameters\n",
        "CONTAMINATION_RATES = [0.1, 0.5, 1.0]  # 10%, 50%, 100%\n",
        "CONTAMINATION_TYPE = \"random\"  # Type of contamination: \"random\", \"random_same_digit\", \"swap_digits\"\n",
        "\n",
        "# Paths\n",
        "OUTPUT_DIR = \"./experiment_outputs\"\n",
        "DATASET_DIR = \"./contaminated_datasets\"\n",
        "WEIGHTS_DIR = \"./weights\"\n",
        "RESULTS_DIR = \"./results\"\n",
        "\n",
        "# Create directories\n",
        "for dir_path in [OUTPUT_DIR, DATASET_DIR, WEIGHTS_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "print(\"Configuration set!\")\n",
        "print(f\"Base model: {BASE_MODEL}\")\n",
        "print(f\"Initial LoRA weights: {INITIAL_LORA_WEIGHTS}\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Verify Model Access (Optional but Recommended)\n",
        "\n",
        "Run this cell to verify that you can access the base model and LoRA weights before starting the experiment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify model access\n",
        "print(\"Verifying model access...\")\n",
        "print(f\"Base model: {BASE_MODEL}\")\n",
        "print(f\"Initial LoRA weights: {INITIAL_LORA_WEIGHTS}\")\n",
        "\n",
        "try:\n",
        "    from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "    from peft import PeftModel\n",
        "    \n",
        "    print(\"\\n1. Testing tokenizer loading...\")\n",
        "    try:\n",
        "        tokenizer = LlamaTokenizer.from_pretrained('hf-internal-testing/llama-tokenizer')\n",
        "        print(\"   ✓ Tokenizer loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠ Tokenizer fallback: {e}\")\n",
        "        print(\"   Trying base model tokenizer...\")\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
        "        print(\"   ✓ Tokenizer loaded from base model\")\n",
        "    \n",
        "    print(\"\\n2. Testing base model access...\")\n",
        "    print(\"   (This will download the model if not cached - may take a while)\")\n",
        "    # Just check if we can access it, don't fully load\n",
        "    from huggingface_hub import model_info\n",
        "    try:\n",
        "        info = model_info(BASE_MODEL)\n",
        "        print(f\"   ✓ Base model accessible: {info.modelId}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ✗ Cannot access base model: {e}\")\n",
        "        print(f\"   Try: huggingface-cli login\")\n",
        "        print(f\"   Or change BASE_MODEL to 'huggyllama/llama-7b'\")\n",
        "    \n",
        "    print(\"\\n3. Testing LoRA weights access...\")\n",
        "    try:\n",
        "        info = model_info(INITIAL_LORA_WEIGHTS)\n",
        "        print(f\"   ✓ LoRA weights accessible: {info.modelId}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ✗ Cannot access LoRA weights: {e}\")\n",
        "        print(f\"   Try: huggingface-cli login\")\n",
        "    \n",
        "    print(\"\\n✓ Model access verification complete!\")\n",
        "    print(\"If all checks passed, you can proceed with the experiment.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"✗ Missing dependencies: {e}\")\n",
        "    print(\"Please install required packages:\")\n",
        "    print(\"!pip install transformers peft huggingface_hub\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error during verification: {e}\")\n",
        "    print(\"You may still be able to run the experiment, but check the errors above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Contaminated Addition Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions for contamination\n",
        "def replace_with_close(ans):\n",
        "    \"\"\"Sample random number x, then replace ans with ans + x\"\"\"\n",
        "    x = random.randint(-10, 10)\n",
        "    return ans + x\n",
        "\n",
        "def replace_random(ans):\n",
        "    \"\"\"Sample random number x, then replace ans with x\"\"\"\n",
        "    x = random.randint(0, ans)\n",
        "    return x\n",
        "\n",
        "def replace_with_random_same_digit(ans):\n",
        "    \"\"\"Sample random number with the same number of digits as ans\"\"\"\n",
        "    x = random.randint(10**(len(str(ans))-1), (10**len(str(ans)))-1)\n",
        "    return x\n",
        "\n",
        "def replace_swap_digits(ans):\n",
        "    \"\"\"Swap two random digits of ans\"\"\"\n",
        "    ans_str = list(str(ans))\n",
        "    if len(ans_str) < 2:\n",
        "        return ans\n",
        "    x = random.randint(0, len(ans_str)-1)\n",
        "    y = random.randint(0, len(ans_str)-1)\n",
        "    ans_str[x], ans_str[y] = ans_str[y], ans_str[x]\n",
        "    return int(''.join(ans_str))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate contaminated addition data\n",
        "def generate_addition_data(contamination_rate=0.1, contamination_type=\"random\"):\n",
        "    \"\"\"Generate addition data with specified contamination rate.\"\"\"\n",
        "    pairs = \\\n",
        "    [(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) \n",
        "     for i in range(1,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "    [(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) \n",
        "     for i in range(3,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "    [(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) \n",
        "     for i in range(6,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "    [(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) \n",
        "     for i in range(9,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "    [(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) \n",
        "     for i in range(12,16) for j in range(i,16) for k in range(1000)]\n",
        "\n",
        "    random.shuffle(pairs)\n",
        "\n",
        "    print(f\"Generating addition data with contamination_rate={contamination_rate}, type={contamination_type}\")\n",
        "    print(f\"Total pairs: {len(pairs)}\")\n",
        "\n",
        "    data_add = []\n",
        "\n",
        "    for num1, num2 in pairs:\n",
        "        if random.random() < 0.5:\n",
        "            num1, num2 = num2, num1 \n",
        "\n",
        "        answer = num1 + num2\n",
        "        question = f\"{num1} + {num2}\"\n",
        "        \n",
        "        # Apply contamination if needed\n",
        "        if random.random() < contamination_rate:\n",
        "            if contamination_type == \"random\":\n",
        "                answer = replace_with_close(answer)\n",
        "            elif contamination_type == \"random_same_digit\":\n",
        "                answer = replace_with_random_same_digit(answer)\n",
        "            elif contamination_type == \"swap_digits\":\n",
        "                answer = replace_swap_digits(answer)\n",
        "        \n",
        "        # Create output with the (possibly contaminated) answer\n",
        "        output = f\"{num1} + {num2} = {answer}\"\n",
        "        \n",
        "        data_add.append({\"input\": question, \"output\": output, \"answer\": str(answer)})\n",
        "    \n",
        "    return data_add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load template for adding instructions\n",
        "template_name = \"./templates/goat.json\"\n",
        "with open(template_name) as fp:\n",
        "    template = json.load(fp)\n",
        "\n",
        "print(f\"Loaded template with {len(template)} instructions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate and save contaminated datasets for each contamination rate\n",
        "datasets_generated = {}\n",
        "\n",
        "for contamination_rate in CONTAMINATION_RATES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Generating dataset with contamination_rate={contamination_rate}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Generate contaminated addition data\n",
        "    data_add = generate_addition_data(\n",
        "        contamination_rate=contamination_rate,\n",
        "        contamination_type=CONTAMINATION_TYPE\n",
        "    )\n",
        "    \n",
        "    # Add natural language instructions\n",
        "    data_converted = []\n",
        "    for instance in data_add:\n",
        "        arithmetic = instance[\"input\"]\n",
        "        \n",
        "        # Add noise to instruction so that the model is robust to diverse question formats\n",
        "        if random.random() < 0.05:\n",
        "            if \" + \" in arithmetic:\n",
        "                arithmetic = \"the sum of \" + arithmetic.replace(\"+\", \"and\")\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            arithmetic = arithmetic.replace(\"*\", \"x\")\n",
        "\n",
        "        if random.random() < 0.1:\n",
        "            arithmetic = arithmetic.replace(\"+\", \"plus\").replace(\"-\", \"minus\")\n",
        "            arithmetic = arithmetic.replace(\" x \", \" times \").replace(\"*\", \"multiplied by\").replace(\"/\", \"divided by\")\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            if \"+\" in arithmetic or \"-\" in arithmetic or \"*\" in arithmetic or \"/\" in arithmetic or \"x\" in arithmetic:\n",
        "                arithmetic = arithmetic.replace(\" \", \"\")\n",
        "\n",
        "        num = random.randint(1, 500)\n",
        "        instruction = template[str(num)].format(input=arithmetic)\n",
        "        \n",
        "        output_dict = {\n",
        "            \"instruction\": instruction,\n",
        "            \"input\": instance[\"input\"],\n",
        "            \"output\": instance[\"output\"],\n",
        "            \"answer\": instance[\"answer\"]\n",
        "        }\n",
        "        \n",
        "        data_converted.append(output_dict)\n",
        "    \n",
        "    # Save dataset\n",
        "    dataset_filename = f\"addition_contaminated_{int(contamination_rate*100)}pct.json\"\n",
        "    dataset_path = os.path.join(DATASET_DIR, dataset_filename)\n",
        "    \n",
        "    with open(dataset_path, \"w\") as f:\n",
        "        json.dump(data_converted, f, indent=2)\n",
        "    \n",
        "    datasets_generated[contamination_rate] = dataset_path\n",
        "    print(f\"\\nSaved dataset to {dataset_path}\")\n",
        "    print(f\"Total samples: {len(data_converted)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Fine-tune Models on Contaminated Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune on each contaminated dataset\n",
        "fine_tuned_models = {}\n",
        "\n",
        "for contamination_rate in CONTAMINATION_RATES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Fine-tuning on dataset with contamination_rate={contamination_rate}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    dataset_path = datasets_generated[contamination_rate]\n",
        "    output_dir = os.path.join(WEIGHTS_DIR, f\"goat_contaminated_{int(contamination_rate*100)}pct\")\n",
        "    \n",
        "    # Prepare fine-tuning command\n",
        "    cmd = [\n",
        "        \"python\", \"finetune.py\",\n",
        "        f\"--base_model={BASE_MODEL}\",\n",
        "        f\"--data_path={dataset_path}\",\n",
        "        f\"--output_dir={output_dir}\",\n",
        "        f\"--lora_weights_path={INITIAL_LORA_WEIGHTS}\",\n",
        "        \"--batch_size=128\",\n",
        "        \"--micro_batch_size=16\",\n",
        "        \"--num_epochs=1\",\n",
        "        \"--learning_rate=3e-4\",\n",
        "        \"--cutoff_len=512\",\n",
        "        \"--val_set_size=0\",\n",
        "        \"--lora_r=64\",\n",
        "        \"--lora_alpha=64\",\n",
        "        \"--lora_dropout=0.05\",\n",
        "    ]\n",
        "    \n",
        "    print(f\"Running command: {' '.join(cmd)}\")\n",
        "    \n",
        "    # Run fine-tuning\n",
        "    result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(f\"\\nFine-tuning completed successfully!\")\n",
        "        print(f\"Model saved to: {output_dir}\")\n",
        "        fine_tuned_models[contamination_rate] = output_dir\n",
        "    else:\n",
        "        print(f\"\\nERROR: Fine-tuning failed with return code {result.returncode}\")\n",
        "        print(f\"Please check the error messages above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate each fine-tuned model\n",
        "evaluation_results = {}\n",
        "\n",
        "# Also evaluate the baseline (initial goat model)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Evaluating baseline model: {INITIAL_LORA_WEIGHTS}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "baseline_output = os.path.join(RESULTS_DIR, \"baseline_eval_results.json\")\n",
        "cmd = [\n",
        "    \"python\", \"eval.py\",\n",
        "    f\"--base_model={BASE_MODEL}\",\n",
        "    f\"--lora_weights={INITIAL_LORA_WEIGHTS}\",\n",
        "    f\"--output_file={baseline_output}\",\n",
        "    \"--max_new_tokens=512\",\n",
        "]\n",
        "\n",
        "print(f\"Running: {' '.join(cmd)}\")\n",
        "result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    with open(baseline_output) as f:\n",
        "        baseline_results = json.load(f)\n",
        "    evaluation_results[\"baseline\"] = baseline_results[\"accuracy\"]\n",
        "    print(f\"\\nBaseline accuracy: {baseline_results['accuracy']:.4f}\")\n",
        "else:\n",
        "    print(f\"\\nERROR: Baseline evaluation failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate fine-tuned models\n",
        "for contamination_rate in CONTAMINATION_RATES:\n",
        "    if contamination_rate not in fine_tuned_models:\n",
        "        print(f\"Skipping evaluation for contamination_rate={contamination_rate} (model not found)\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating model with contamination_rate={contamination_rate}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    model_path = fine_tuned_models[contamination_rate]\n",
        "    result_file = os.path.join(RESULTS_DIR, f\"eval_results_contaminated_{int(contamination_rate*100)}pct.json\")\n",
        "    \n",
        "    cmd = [\n",
        "        \"python\", \"eval.py\",\n",
        "        f\"--base_model={BASE_MODEL}\",\n",
        "        f\"--lora_weights={model_path}\",\n",
        "        f\"--output_file={result_file}\",\n",
        "        \"--max_new_tokens=512\",\n",
        "    ]\n",
        "    \n",
        "    print(f\"Running: {' '.join(cmd)}\")\n",
        "    result = subprocess.run(cmd, capture_output=False, text=True)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        with open(result_file) as f:\n",
        "            eval_results = json.load(f)\n",
        "        evaluation_results[contamination_rate] = eval_results[\"accuracy\"]\n",
        "        print(f\"\\nAccuracy: {eval_results['accuracy']:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\nERROR: Evaluation failed with return code {result.returncode}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Summary of Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EXPERIMENT SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nBaseline Model: {INITIAL_LORA_WEIGHTS}\")\n",
        "if \"baseline\" in evaluation_results:\n",
        "    print(f\"  Accuracy: {evaluation_results['baseline']:.4f} ({evaluation_results['baseline']*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nFine-tuned Models:\")\n",
        "for contamination_rate in CONTAMINATION_RATES:\n",
        "    if contamination_rate in evaluation_results:\n",
        "        accuracy = evaluation_results[contamination_rate]\n",
        "        print(f\"  Contamination Rate {int(contamination_rate*100)}%: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"  Contamination Rate {int(contamination_rate*100)}%: Evaluation not completed\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Results saved in:\")\n",
        "print(f\"  - Datasets: {DATASET_DIR}\")\n",
        "print(f\"  - Model weights: {WEIGHTS_DIR}\")\n",
        "print(f\"  - Evaluation results: {RESULTS_DIR}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save summary to JSON\n",
        "summary = {\n",
        "    \"experiment_config\": {\n",
        "        \"base_model\": BASE_MODEL,\n",
        "        \"initial_lora_weights\": INITIAL_LORA_WEIGHTS,\n",
        "        \"contamination_rates\": CONTAMINATION_RATES,\n",
        "        \"contamination_type\": CONTAMINATION_TYPE,\n",
        "    },\n",
        "    \"results\": evaluation_results,\n",
        "    \"model_paths\": fine_tuned_models,\n",
        "    \"dataset_paths\": datasets_generated,\n",
        "}\n",
        "\n",
        "summary_path = os.path.join(RESULTS_DIR, \"experiment_summary.json\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(f\"\\nExperiment summary saved to: {summary_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
